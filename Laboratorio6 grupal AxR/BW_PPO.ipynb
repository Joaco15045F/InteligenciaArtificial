{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 6 Grupal \"Aprendizaje por Refuerzo\".\n",
    "#### Nombres:\n",
    "####          - Aramayo Valdez Joaquin.\n",
    "####          - Piza Nava Vladimir.\n",
    "####          - Viza Hoyos Maria Belen.\n",
    "####          - Mendoza Ovando Carlos Saul.\n",
    "####          - Solorzano Diego.\n",
    "#### Link GitHub: https://github.com/Joaco15045F/InteligenciaArtificial/blob/main/Laboratorio6%20grupal%20AxR/Lab6_BipedalWalker.ipynb\n",
    "#### Link info BipedalWalker: https://www.gymlibrary.dev/environments/box2d/bipedal_walker/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de Librerías\n",
    "#### Importamos las librerías clave para configurar y entrenar un modelo de aprendizaje por refuerzo. gymnasium crea el entorno de simulación, PPO aplica el algoritmo de entrenamiento, y EvalCallback permite evaluar y guardar el mejor modelo. Además, se importan herramientas para normalizar datos y vectorizar el entorno, y otras librerías para la gestión de archivos, visualización y cálculos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías necesarias para el entrenamiento de aprendizaje por refuerzo\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración del Entorno y del Modelo\n",
    "#### Definimos el entorno de simulación y la ruta donde se guardará el modelo entrenado. ENV_NAME establece el entorno BipedalWalker-v3, y MODEL_PATH define el nombre del archivo para el modelo guardado. Se crea el entorno vectorizado (DummyVecEnv), configurado para renderizar en modo humano, permitiendo observar el entrenamiento en tiempo real. Además, se normalizan las observaciones y recompensas (VecNormalize) para estabilizar el aprendizaje del agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el nombre del entorno y la ruta para guardar el modelo entrenado\n",
    "ENV_NAME = \"BipedalWalker-v3\"\n",
    "MODEL_PATH = \"ppo_bipedalwalker\"\n",
    "\n",
    "# Crear el entorno con la opción de renderizar en modo humano para observar el entrenamiento en tiempo real\n",
    "env = DummyVecEnv([lambda: gym.make(ENV_NAME, render_mode=\"human\")])  # Vectorizar y renderizar\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True)  # Normalizar observaciones y recompensas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del Modelo\n",
    "#### Creamos y configuramos el modelo de aprendizaje por refuerzo utilizando el algoritmo PPO. Se especifica MlpPolicy, una red neuronal basada en perceptrones multicapa, como política de entrenamiento, y se asocia al entorno env. Los parámetros ajustan el modelo para un aprendizaje efectivo: learning_rate controla la tasa de aprendizaje, n_steps define el número de pasos por actualización, batch_size el tamaño de cada lote, n_epochs las épocas de entrenamiento, y gamma el factor de descuento que pondera recompensas futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=0.0003, n_steps=2048, batch_size=64, n_epochs=10, gamma=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de Callbacks para guardar el mejor modelo\n",
    "#### En esta parte creamos un entorno de evaluación eval_env, similar al entorno de entrenamiento, con normalización de observaciones y recompensas para asegurar consistencia. Luego, configura eval_callback, un callback que evalúa el modelo cada 5000 pasos (eval_freq). También guardamos el mejor modelo en MODEL_PATH y registra el progreso en la carpeta ./logs/, ayudando a monitorear y conservar el mejor rendimiento durante el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = DummyVecEnv([lambda: gym.make(ENV_NAME)])\n",
    "eval_env = VecNormalize(eval_env, norm_obs=True, norm_reward=True)\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path=MODEL_PATH, log_path='./logs/', eval_freq=5000, deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo\n",
    "#### Ahora lo que hacemos es entrenar el modelo de aprendizaje por refuerzo durante 100,000 pasos (total_timesteps). En cada paso, el modelo selecciona una acción basada en el entorno observado, que luego se ejecuta para obtener una recompensa. Las recompensas acumuladas por episodio se almacenan en la lista rewards. Durante el entrenamiento, el entorno se renderiza y se ajusta la velocidad de visualización. Al finalizar cada episodio, el entorno se reinicia. eval_callback evalúa periódicamente el modelo, y finalmente, el modelo entrenado se guarda en MODEL_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo y registrando recompensas por episodio...\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 48   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 42   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 48   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 42   |\n",
      "|    total_timesteps | 4096 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaco\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5000, episode_reward=-13.83 +/- 0.53\n",
      "Episode length: 90.20 +/- 16.53\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 90.2     |\n",
      "|    mean_reward     | -13.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 5000     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 47   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 43   |\n",
      "|    total_timesteps | 6144 |\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 48   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 42   |\n",
      "|    total_timesteps | 8192 |\n",
      "-----------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-7.60 +/- 0.46\n",
      "Episode length: 100.00 +/- 2.90\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 100      |\n",
      "|    mean_reward     | -7.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 10000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 47    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 43    |\n",
      "|    total_timesteps | 10240 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 14336 |\n",
      "------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-8.62 +/- 0.91\n",
      "Episode length: 91.80 +/- 10.30\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 91.8     |\n",
      "|    mean_reward     | -8.62    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 15000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 47    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 43    |\n",
      "|    total_timesteps | 16384 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 47    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 43    |\n",
      "|    total_timesteps | 18432 |\n",
      "------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-10.04 +/- 1.12\n",
      "Episode length: 92.00 +/- 3.41\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 92       |\n",
      "|    mean_reward     | -10      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 20000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 47    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 20480 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 22528 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 24576 |\n",
      "------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-9.41 +/- 0.35\n",
      "Episode length: 137.20 +/- 4.79\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 137      |\n",
      "|    mean_reward     | -9.41    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 25000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 47    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 43    |\n",
      "|    total_timesteps | 26624 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 28672 |\n",
      "------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-10.60 +/- 1.74\n",
      "Episode length: 419.60 +/- 590.23\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 420      |\n",
      "|    mean_reward     | -10.6    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 30000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 46    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 44    |\n",
      "|    total_timesteps | 30720 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 34816 |\n",
      "------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-8.63 +/- 0.25\n",
      "Episode length: 100.60 +/- 4.13\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 101      |\n",
      "|    mean_reward     | -8.63    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 35000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 47    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 36864 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 38912 |\n",
      "------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-6.58 +/- 4.35\n",
      "Episode length: 286.40 +/- 371.52\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 286      |\n",
      "|    mean_reward     | -6.58    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 40000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 46    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 43    |\n",
      "|    total_timesteps | 40960 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 43008 |\n",
      "------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=13.28 +/- 13.08\n",
      "Episode length: 1223.20 +/- 572.24\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.22e+03 |\n",
      "|    mean_reward     | 13.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 45000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 43    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 47    |\n",
      "|    total_timesteps | 45056 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 47104 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 49152 |\n",
      "------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=12.62 +/- 10.32\n",
      "Episode length: 1054.40 +/- 360.21\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.05e+03 |\n",
      "|    mean_reward     | 12.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 50000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 43    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 46    |\n",
      "|    total_timesteps | 51200 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 53248 |\n",
      "------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-9.50 +/- 0.07\n",
      "Episode length: 78.00 +/- 1.67\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 78       |\n",
      "|    mean_reward     | -9.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 55000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 55296 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 57344 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 47    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 59392 |\n",
      "------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-3.69 +/- 8.83\n",
      "Episode length: 522.00 +/- 513.38\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 522      |\n",
      "|    mean_reward     | -3.69    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 60000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 45    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 45    |\n",
      "|    total_timesteps | 61440 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 63488 |\n",
      "------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-9.68 +/- 0.09\n",
      "Episode length: 96.60 +/- 3.44\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 96.6     |\n",
      "|    mean_reward     | -9.68    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 65000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 47    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 65536 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 67584 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 69632 |\n",
      "------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-9.72 +/- 0.04\n",
      "Episode length: 66.40 +/- 7.50\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 66.4     |\n",
      "|    mean_reward     | -9.72    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 70000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 47    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 71680 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 73728 |\n",
      "------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-3.85 +/- 2.68\n",
      "Episode length: 247.20 +/- 123.01\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 247      |\n",
      "|    mean_reward     | -3.85    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 75000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 47    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 43    |\n",
      "|    total_timesteps | 75776 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 77824 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 79872 |\n",
      "------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-4.94 +/- 3.22\n",
      "Episode length: 290.20 +/- 115.89\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 290      |\n",
      "|    mean_reward     | -4.94    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 80000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 46    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 43    |\n",
      "|    total_timesteps | 81920 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 83968 |\n",
      "------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-5.96 +/- 3.60\n",
      "Episode length: 307.40 +/- 164.73\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 307      |\n",
      "|    mean_reward     | -5.96    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 85000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 46    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 43    |\n",
      "|    total_timesteps | 86016 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 88064 |\n",
      "------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-2.31 +/- 5.61\n",
      "Episode length: 484.80 +/- 218.63\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 485      |\n",
      "|    mean_reward     | -2.31    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 90000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 46    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 44    |\n",
      "|    total_timesteps | 90112 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 92160 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 47    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 94208 |\n",
      "------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=-3.75 +/- 3.06\n",
      "Episode length: 261.40 +/- 98.81\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 261      |\n",
      "|    mean_reward     | -3.75    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 95000    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 46    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 43    |\n",
      "|    total_timesteps | 96256 |\n",
      "------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 48    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 42    |\n",
      "|    total_timesteps | 98304 |\n",
      "------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-4.83 +/- 2.02\n",
      "Episode length: 253.80 +/- 91.97\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 254      |\n",
      "|    mean_reward     | -4.83    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 100000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 47     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 43     |\n",
      "|    total_timesteps | 100352 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 102400 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 104448 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-5.81 +/- 1.87\n",
      "Episode length: 222.20 +/- 76.79\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 222      |\n",
      "|    mean_reward     | -5.81    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 105000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 47     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 43     |\n",
      "|    total_timesteps | 106496 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 108544 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-4.54 +/- 1.56\n",
      "Episode length: 271.00 +/- 55.70\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 271      |\n",
      "|    mean_reward     | -4.54    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 110000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 46     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 43     |\n",
      "|    total_timesteps | 110592 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 112640 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 114688 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-4.00 +/- 6.38\n",
      "Episode length: 492.60 +/- 345.15\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 493      |\n",
      "|    mean_reward     | -4       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 115000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 46     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 44     |\n",
      "|    total_timesteps | 116736 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 118784 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-2.56 +/- 5.44\n",
      "Episode length: 419.20 +/- 192.21\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 419      |\n",
      "|    mean_reward     | -2.56    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 120000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 46     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 44     |\n",
      "|    total_timesteps | 120832 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 122880 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 124928 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-5.68 +/- 3.52\n",
      "Episode length: 250.80 +/- 108.45\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 251      |\n",
      "|    mean_reward     | -5.68    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 125000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 47     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 43     |\n",
      "|    total_timesteps | 126976 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 129024 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-1.13 +/- 5.55\n",
      "Episode length: 447.60 +/- 201.48\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 448      |\n",
      "|    mean_reward     | -1.13    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 130000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 46     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 44     |\n",
      "|    total_timesteps | 131072 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 133120 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=6.54 +/- 15.16\n",
      "Episode length: 659.40 +/- 512.15\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 659      |\n",
      "|    mean_reward     | 6.54     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 135000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 135168 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 137216 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 139264 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=24.88 +/- 15.59\n",
      "Episode length: 1246.60 +/- 400.73\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.25e+03 |\n",
      "|    mean_reward     | 24.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 140000   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 141312 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 143360 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=10.98 +/- 14.70\n",
      "Episode length: 837.00 +/- 436.33\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 837      |\n",
      "|    mean_reward     | 11       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 145000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 145408 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 147456 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 149504 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=9.39 +/- 15.76\n",
      "Episode length: 818.40 +/- 490.47\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 818      |\n",
      "|    mean_reward     | 9.39     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 150000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 151552 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 153600 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=3.22 +/- 9.00\n",
      "Episode length: 574.80 +/- 344.71\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 575      |\n",
      "|    mean_reward     | 3.22     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 155000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 44     |\n",
      "|    total_timesteps | 155648 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 157696 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 159744 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-0.62 +/- 4.17\n",
      "Episode length: 405.40 +/- 164.79\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 405      |\n",
      "|    mean_reward     | -0.619   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 160000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 46     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 43     |\n",
      "|    total_timesteps | 161792 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 163840 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=5.77 +/- 7.23\n",
      "Episode length: 689.60 +/- 284.16\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 690      |\n",
      "|    mean_reward     | 5.77     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 165000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 165888 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 167936 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 169984 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=27.62 +/- 14.49\n",
      "Episode length: 1284.80 +/- 453.40\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.28e+03 |\n",
      "|    mean_reward     | 27.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 170000   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 172032 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 174080 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=21.83 +/- 16.96\n",
      "Episode length: 1009.20 +/- 469.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.01e+03 |\n",
      "|    mean_reward     | 21.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 175000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 176128 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 178176 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=17.07 +/- 11.23\n",
      "Episode length: 1013.80 +/- 291.55\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.01e+03 |\n",
      "|    mean_reward     | 17.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 180000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 180224 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 182272 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 184320 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=17.09 +/- 17.05\n",
      "Episode length: 899.40 +/- 471.18\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 899      |\n",
      "|    mean_reward     | 17.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 185000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 186368 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 188416 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=27.08 +/- 16.09\n",
      "Episode length: 1113.80 +/- 436.73\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.11e+03 |\n",
      "|    mean_reward     | 27.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 190000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 190464 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 192512 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 194560 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=32.74 +/- 4.35\n",
      "Episode length: 1365.00 +/- 124.82\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.36e+03 |\n",
      "|    mean_reward     | 32.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 195000   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 42     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 196608 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 198656 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=12.59 +/- 17.81\n",
      "Episode length: 854.00 +/- 465.04\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 854      |\n",
      "|    mean_reward     | 12.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 200000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 200704 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 202752 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 204800 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=205000, episode_reward=29.69 +/- 8.19\n",
      "Episode length: 1303.40 +/- 201.04\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.3e+03  |\n",
      "|    mean_reward     | 29.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 205000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 206848 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 208896 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=22.86 +/- 13.87\n",
      "Episode length: 1091.40 +/- 287.45\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.09e+03 |\n",
      "|    mean_reward     | 22.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 210000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 210944 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 212992 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=12.72 +/- 17.64\n",
      "Episode length: 793.20 +/- 490.48\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 793      |\n",
      "|    mean_reward     | 12.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 215000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 215040 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 217088 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 219136 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=27.83 +/- 12.30\n",
      "Episode length: 1179.80 +/- 337.66\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.18e+03 |\n",
      "|    mean_reward     | 27.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 220000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 221184 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 223232 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=21.27 +/- 16.48\n",
      "Episode length: 910.40 +/- 395.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 910      |\n",
      "|    mean_reward     | 21.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 225000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 225280 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 227328 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 229376 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-1.29 +/- 7.42\n",
      "Episode length: 338.40 +/- 246.86\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 338      |\n",
      "|    mean_reward     | -1.29    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 230000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 46     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 43     |\n",
      "|    total_timesteps | 231424 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 233472 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=25.44 +/- 7.43\n",
      "Episode length: 1212.60 +/- 37.28\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.21e+03 |\n",
      "|    mean_reward     | 25.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 235000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 42     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 48     |\n",
      "|    total_timesteps | 235520 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 237568 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 239616 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=21.77 +/- 14.74\n",
      "Episode length: 969.60 +/- 384.49\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 970      |\n",
      "|    mean_reward     | 21.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 240000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 241664 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 243712 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=7.51 +/- 14.11\n",
      "Episode length: 639.80 +/- 385.19\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 640      |\n",
      "|    mean_reward     | 7.51     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 245000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 44     |\n",
      "|    total_timesteps | 245760 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 247808 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 249856 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=21.10 +/- 15.54\n",
      "Episode length: 927.20 +/- 359.87\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 927      |\n",
      "|    mean_reward     | 21.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 250000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 251904 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 253952 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=255000, episode_reward=4.73 +/- 8.90\n",
      "Episode length: 604.20 +/- 327.19\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 604      |\n",
      "|    mean_reward     | 4.73     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 255000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 44     |\n",
      "|    total_timesteps | 256000 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 258048 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=20.11 +/- 16.35\n",
      "Episode length: 922.60 +/- 391.67\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 923      |\n",
      "|    mean_reward     | 20.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 260000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 260096 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 262144 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 264192 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=5.85 +/- 9.53\n",
      "Episode length: 675.20 +/- 372.46\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 675      |\n",
      "|    mean_reward     | 5.85     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 265000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 266240 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 268288 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=13.61 +/- 16.16\n",
      "Episode length: 775.60 +/- 415.03\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 776      |\n",
      "|    mean_reward     | 13.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 270000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 270336 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 272384 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 274432 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=8.94 +/- 12.56\n",
      "Episode length: 690.20 +/- 329.96\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 690      |\n",
      "|    mean_reward     | 8.94     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 275000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 276480 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 278528 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=4.40 +/- 5.41\n",
      "Episode length: 598.60 +/- 221.57\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 599      |\n",
      "|    mean_reward     | 4.4      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 280000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 280576 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 282624 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 284672 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=18.56 +/- 8.41\n",
      "Episode length: 1047.40 +/- 196.62\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.05e+03 |\n",
      "|    mean_reward     | 18.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 285000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 286720 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 288768 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=5.35 +/- 14.84\n",
      "Episode length: 557.80 +/- 400.92\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 558      |\n",
      "|    mean_reward     | 5.35     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 290000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 44     |\n",
      "|    total_timesteps | 290816 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 292864 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 294912 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=14.77 +/- 10.50\n",
      "Episode length: 913.40 +/- 280.11\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 913      |\n",
      "|    mean_reward     | 14.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 295000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 296960 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 299008 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=2.29 +/- 4.65\n",
      "Episode length: 538.60 +/- 204.47\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 539      |\n",
      "|    mean_reward     | 2.29     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 300000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 44     |\n",
      "|    total_timesteps | 301056 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 303104 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=305000, episode_reward=19.40 +/- 13.59\n",
      "Episode length: 1035.80 +/- 446.68\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.04e+03 |\n",
      "|    mean_reward     | 19.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 305000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 305152 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 307200 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 309248 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=13.65 +/- 10.77\n",
      "Episode length: 918.60 +/- 290.42\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 919      |\n",
      "|    mean_reward     | 13.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 310000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 311296 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 313344 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=315000, episode_reward=12.07 +/- 10.51\n",
      "Episode length: 826.40 +/- 202.79\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 826      |\n",
      "|    mean_reward     | 12.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 315000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 315392 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 317440 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 319488 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=14.16 +/- 14.48\n",
      "Episode length: 1071.20 +/- 433.83\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.07e+03 |\n",
      "|    mean_reward     | 14.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 320000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 321536 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 323584 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=22.48 +/- 12.33\n",
      "Episode length: 1101.80 +/- 326.68\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.1e+03  |\n",
      "|    mean_reward     | 22.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 325000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 325632 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 327680 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 329728 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=31.12 +/- 0.51\n",
      "Episode length: 1258.00 +/- 60.54\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.26e+03 |\n",
      "|    mean_reward     | 31.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 330000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 42     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 331776 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 333824 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=335000, episode_reward=26.15 +/- 10.59\n",
      "Episode length: 1123.80 +/- 213.27\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.12e+03 |\n",
      "|    mean_reward     | 26.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 335000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 335872 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 337920 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 339968 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=26.20 +/- 10.39\n",
      "Episode length: 1135.40 +/- 169.92\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.14e+03 |\n",
      "|    mean_reward     | 26.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 340000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 342016 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 344064 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=345000, episode_reward=24.03 +/- 9.29\n",
      "Episode length: 1111.20 +/- 193.84\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.11e+03 |\n",
      "|    mean_reward     | 24       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 345000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 42     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 346112 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 348160 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=19.02 +/- 15.47\n",
      "Episode length: 913.60 +/- 367.84\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 914      |\n",
      "|    mean_reward     | 19       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 350000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 350208 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 352256 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 354304 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=355000, episode_reward=30.72 +/- 0.45\n",
      "Episode length: 1259.80 +/- 41.91\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.26e+03 |\n",
      "|    mean_reward     | 30.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 355000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 356352 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 47     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 358400 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=24.28 +/- 13.58\n",
      "Episode length: 1092.60 +/- 259.42\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.09e+03 |\n",
      "|    mean_reward     | 24.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 360000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 360448 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 362496 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 364544 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=365000, episode_reward=30.79 +/- 0.30\n",
      "Episode length: 1251.40 +/- 43.55\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.25e+03 |\n",
      "|    mean_reward     | 30.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 365000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 42     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 366592 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 368640 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=28.47 +/- 4.09\n",
      "Episode length: 1353.60 +/- 140.46\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.35e+03 |\n",
      "|    mean_reward     | 28.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 370000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 42     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 48     |\n",
      "|    total_timesteps | 370688 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 47     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 372736 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 47     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 374784 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=30.77 +/- 0.45\n",
      "Episode length: 1257.40 +/- 56.74\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.26e+03 |\n",
      "|    mean_reward     | 30.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 375000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 42     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 376832 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 378880 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=26.49 +/- 8.98\n",
      "Episode length: 1138.00 +/- 146.33\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.14e+03 |\n",
      "|    mean_reward     | 26.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 380000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 380928 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 382976 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=385000, episode_reward=30.75 +/- 0.27\n",
      "Episode length: 1238.20 +/- 24.24\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.24e+03 |\n",
      "|    mean_reward     | 30.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 385000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 385024 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 387072 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 389120 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=31.07 +/- 0.07\n",
      "Episode length: 1189.00 +/- 16.15\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 31.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 390000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 391168 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 393216 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=395000, episode_reward=31.07 +/- 0.49\n",
      "Episode length: 1221.40 +/- 62.01\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.22e+03 |\n",
      "|    mean_reward     | 31.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 395000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 42     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 395264 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 397312 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 399360 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=30.77 +/- 0.48\n",
      "Episode length: 1230.80 +/- 61.32\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.23e+03 |\n",
      "|    mean_reward     | 30.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 400000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 401408 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 403456 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=405000, episode_reward=28.37 +/- 4.77\n",
      "Episode length: 1251.00 +/- 74.95\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.25e+03 |\n",
      "|    mean_reward     | 28.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 405000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 405504 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 407552 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 409600 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=30.82 +/- 0.42\n",
      "Episode length: 1206.20 +/- 40.67\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.21e+03 |\n",
      "|    mean_reward     | 30.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 410000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 411648 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 413696 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=415000, episode_reward=30.70 +/- 0.29\n",
      "Episode length: 1231.20 +/- 38.39\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.23e+03 |\n",
      "|    mean_reward     | 30.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 415000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 42     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 48     |\n",
      "|    total_timesteps | 415744 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 46     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 43     |\n",
      "|    total_timesteps | 417792 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 419840 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=30.59 +/- 0.29\n",
      "Episode length: 1269.00 +/- 42.43\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.27e+03 |\n",
      "|    mean_reward     | 30.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 420000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 421888 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 423936 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=31.01 +/- 0.23\n",
      "Episode length: 1205.20 +/- 39.55\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.21e+03 |\n",
      "|    mean_reward     | 31       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 425000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 425984 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 428032 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=30.88 +/- 0.38\n",
      "Episode length: 1206.40 +/- 31.26\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.21e+03 |\n",
      "|    mean_reward     | 30.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 430000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 430080 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 432128 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 434176 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=435000, episode_reward=30.88 +/- 0.32\n",
      "Episode length: 1201.20 +/- 41.83\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 30.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 435000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 436224 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 438272 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=31.06 +/- 0.12\n",
      "Episode length: 1190.20 +/- 13.08\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 31.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 440000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 440320 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 442368 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 444416 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=445000, episode_reward=30.76 +/- 0.37\n",
      "Episode length: 1207.00 +/- 42.37\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.21e+03 |\n",
      "|    mean_reward     | 30.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 445000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 446464 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 448512 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=31.25 +/- 0.20\n",
      "Episode length: 1177.20 +/- 25.32\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.18e+03 |\n",
      "|    mean_reward     | 31.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 450000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 450560 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 452608 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 454656 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=455000, episode_reward=31.35 +/- 0.31\n",
      "Episode length: 1159.40 +/- 27.73\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 31.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 455000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 456704 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 458752 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=24.83 +/- 12.34\n",
      "Episode length: 1086.40 +/- 233.36\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.09e+03 |\n",
      "|    mean_reward     | 24.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 460000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 460800 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 462848 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 464896 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=465000, episode_reward=25.37 +/- 11.33\n",
      "Episode length: 1065.00 +/- 252.86\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.06e+03 |\n",
      "|    mean_reward     | 25.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 465000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 466944 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 468992 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=31.16 +/- 0.10\n",
      "Episode length: 1160.60 +/- 22.04\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 31.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 470000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 471040 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 473088 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=28.12 +/- 6.37\n",
      "Episode length: 1240.40 +/- 180.12\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.24e+03 |\n",
      "|    mean_reward     | 28.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 475000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 475136 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 477184 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 479232 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=31.25 +/- 0.22\n",
      "Episode length: 1140.00 +/- 21.75\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.14e+03 |\n",
      "|    mean_reward     | 31.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 480000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 481280 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 483328 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=485000, episode_reward=30.39 +/- 0.52\n",
      "Episode length: 1275.20 +/- 59.72\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.28e+03 |\n",
      "|    mean_reward     | 30.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 485000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 485376 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 487424 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 489472 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=30.97 +/- 0.57\n",
      "Episode length: 1182.60 +/- 86.49\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.18e+03 |\n",
      "|    mean_reward     | 31       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 490000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 491520 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 493568 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=495000, episode_reward=31.17 +/- 0.22\n",
      "Episode length: 1161.20 +/- 33.11\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 31.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 495000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 495616 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 497664 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 499712 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=31.10 +/- 0.34\n",
      "Episode length: 1158.80 +/- 42.13\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 31.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 500000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 501760 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 503808 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=505000, episode_reward=30.93 +/- 0.11\n",
      "Episode length: 1201.60 +/- 27.23\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 30.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 505000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 505856 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 507904 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 509952 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=31.11 +/- 0.29\n",
      "Episode length: 1180.60 +/- 30.50\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.18e+03 |\n",
      "|    mean_reward     | 31.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 510000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 512000 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 514048 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=515000, episode_reward=31.17 +/- 0.46\n",
      "Episode length: 1175.60 +/- 48.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.18e+03 |\n",
      "|    mean_reward     | 31.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 515000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 516096 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 518144 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=30.91 +/- 0.41\n",
      "Episode length: 1211.20 +/- 44.56\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.21e+03 |\n",
      "|    mean_reward     | 30.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 520000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 520192 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 522240 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 524288 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=525000, episode_reward=30.98 +/- 0.32\n",
      "Episode length: 1195.60 +/- 42.45\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 31       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 525000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 526336 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 528384 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=26.87 +/- 7.71\n",
      "Episode length: 1132.40 +/- 149.07\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.13e+03 |\n",
      "|    mean_reward     | 26.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 530000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 530432 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 532480 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 534528 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=535000, episode_reward=30.55 +/- 0.50\n",
      "Episode length: 1241.40 +/- 63.32\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.24e+03 |\n",
      "|    mean_reward     | 30.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 535000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 536576 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 538624 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=31.19 +/- 0.34\n",
      "Episode length: 1170.20 +/- 31.88\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.17e+03 |\n",
      "|    mean_reward     | 31.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 540000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 540672 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 542720 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 544768 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=545000, episode_reward=30.91 +/- 0.47\n",
      "Episode length: 1194.00 +/- 50.20\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 30.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 545000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 546816 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 548864 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=31.02 +/- 0.23\n",
      "Episode length: 1171.60 +/- 32.95\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.17e+03 |\n",
      "|    mean_reward     | 31       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 550000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 550912 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 552960 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=555000, episode_reward=30.96 +/- 0.14\n",
      "Episode length: 1200.40 +/- 13.22\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 31       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 555000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 555008 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 557056 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 559104 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=30.79 +/- 0.26\n",
      "Episode length: 1215.80 +/- 34.23\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.22e+03 |\n",
      "|    mean_reward     | 30.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 560000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 561152 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 563200 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=565000, episode_reward=30.73 +/- 0.43\n",
      "Episode length: 1227.00 +/- 49.95\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.23e+03 |\n",
      "|    mean_reward     | 30.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 565000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 565248 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 567296 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 569344 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=31.00 +/- 0.25\n",
      "Episode length: 1199.40 +/- 34.21\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 31       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 570000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 571392 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 573440 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=575000, episode_reward=23.94 +/- 14.40\n",
      "Episode length: 1003.00 +/- 367.88\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 23.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 575000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 575488 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 577536 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 579584 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=30.93 +/- 0.17\n",
      "Episode length: 1201.20 +/- 25.40\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 30.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 580000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 581632 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 583680 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=585000, episode_reward=24.02 +/- 14.15\n",
      "Episode length: 1017.80 +/- 358.70\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.02e+03 |\n",
      "|    mean_reward     | 24       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 585000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 585728 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 587776 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 589824 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=31.12 +/- 0.33\n",
      "Episode length: 1198.80 +/- 48.34\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 31.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 590000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 591872 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 593920 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=595000, episode_reward=24.03 +/- 14.32\n",
      "Episode length: 1001.20 +/- 373.41\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 24       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 595000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 595968 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 598016 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=25.00 +/- 12.43\n",
      "Episode length: 1050.40 +/- 278.08\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.05e+03 |\n",
      "|    mean_reward     | 25       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 600000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 600064 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 602112 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 604160 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=605000, episode_reward=31.26 +/- 0.24\n",
      "Episode length: 1179.60 +/- 23.02\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.18e+03 |\n",
      "|    mean_reward     | 31.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 605000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 606208 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 608256 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=31.07 +/- 0.34\n",
      "Episode length: 1195.40 +/- 31.99\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 31.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 610000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 610304 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 612352 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 614400 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=615000, episode_reward=31.14 +/- 0.31\n",
      "Episode length: 1206.20 +/- 44.14\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.21e+03 |\n",
      "|    mean_reward     | 31.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 615000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 616448 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 618496 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=31.25 +/- 0.21\n",
      "Episode length: 1174.60 +/- 15.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.17e+03 |\n",
      "|    mean_reward     | 31.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 620000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 620544 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 622592 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 624640 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=625000, episode_reward=27.67 +/- 6.72\n",
      "Episode length: 1168.20 +/- 85.46\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.17e+03 |\n",
      "|    mean_reward     | 27.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 625000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 626688 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 628736 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=31.13 +/- 0.31\n",
      "Episode length: 1189.60 +/- 25.94\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 31.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 630000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 630784 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 632832 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 634880 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=635000, episode_reward=31.27 +/- 0.25\n",
      "Episode length: 1192.80 +/- 29.98\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 31.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 635000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 636928 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 638976 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=30.75 +/- 0.25\n",
      "Episode length: 1239.60 +/- 41.22\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.24e+03 |\n",
      "|    mean_reward     | 30.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 640000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 641024 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 643072 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=645000, episode_reward=31.18 +/- 0.28\n",
      "Episode length: 1188.20 +/- 21.66\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 31.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 645000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 645120 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 647168 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 649216 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=30.84 +/- 0.19\n",
      "Episode length: 1224.00 +/- 33.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.22e+03 |\n",
      "|    mean_reward     | 30.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 650000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 651264 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 653312 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=655000, episode_reward=31.26 +/- 0.30\n",
      "Episode length: 1178.60 +/- 37.38\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.18e+03 |\n",
      "|    mean_reward     | 31.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 655000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 655360 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 657408 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 659456 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=30.98 +/- 0.28\n",
      "Episode length: 1218.40 +/- 27.41\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.22e+03 |\n",
      "|    mean_reward     | 31       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 660000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 661504 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 663552 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=665000, episode_reward=27.47 +/- 7.55\n",
      "Episode length: 1116.60 +/- 124.37\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.12e+03 |\n",
      "|    mean_reward     | 27.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 665000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 665600 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 667648 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 669696 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=30.90 +/- 0.28\n",
      "Episode length: 1217.00 +/- 43.95\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.22e+03 |\n",
      "|    mean_reward     | 30.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 670000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 671744 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 47     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 673792 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=675000, episode_reward=28.09 +/- 5.81\n",
      "Episode length: 1153.60 +/- 82.05\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.15e+03 |\n",
      "|    mean_reward     | 28.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 675000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 675840 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 677888 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 679936 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=31.20 +/- 0.26\n",
      "Episode length: 1187.80 +/- 27.42\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 31.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 680000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 681984 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 684032 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=685000, episode_reward=31.01 +/- 0.05\n",
      "Episode length: 1197.20 +/- 10.72\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 31       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 685000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 686080 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 688128 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=31.01 +/- 0.33\n",
      "Episode length: 1212.20 +/- 30.83\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.21e+03 |\n",
      "|    mean_reward     | 31       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 690000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 690176 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 692224 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 694272 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=695000, episode_reward=30.98 +/- 0.13\n",
      "Episode length: 1200.60 +/- 12.48\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 31       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 695000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 696320 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 698368 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=26.97 +/- 8.74\n",
      "Episode length: 1095.80 +/- 166.32\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.1e+03  |\n",
      "|    mean_reward     | 27       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 700000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 700416 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 702464 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 704512 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=705000, episode_reward=24.14 +/- 8.71\n",
      "Episode length: 1162.40 +/- 132.21\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 24.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 705000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 706560 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 708608 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=30.66 +/- 0.64\n",
      "Episode length: 1268.60 +/- 103.72\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.27e+03 |\n",
      "|    mean_reward     | 30.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 710000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 710656 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 712704 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 714752 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=715000, episode_reward=26.10 +/- 10.31\n",
      "Episode length: 1262.40 +/- 171.67\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.26e+03 |\n",
      "|    mean_reward     | 26.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 715000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 716800 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 718848 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=24.62 +/- 12.81\n",
      "Episode length: 1289.80 +/- 155.55\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.29e+03 |\n",
      "|    mean_reward     | 24.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 720000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 720896 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 722944 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 724992 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=725000, episode_reward=27.11 +/- 8.07\n",
      "Episode length: 1128.60 +/- 136.17\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.13e+03 |\n",
      "|    mean_reward     | 27.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 725000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 727040 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 729088 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=30.65 +/- 0.53\n",
      "Episode length: 1235.80 +/- 61.05\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.24e+03 |\n",
      "|    mean_reward     | 30.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 730000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 731136 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 733184 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=735000, episode_reward=24.81 +/- 11.95\n",
      "Episode length: 1084.00 +/- 279.42\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.08e+03 |\n",
      "|    mean_reward     | 24.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 735000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 735232 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 737280 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 739328 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=24.02 +/- 14.57\n",
      "Episode length: 993.60 +/- 366.57\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 994      |\n",
      "|    mean_reward     | 24       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 740000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 741376 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 743424 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=745000, episode_reward=23.79 +/- 9.03\n",
      "Episode length: 1070.40 +/- 178.70\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.07e+03 |\n",
      "|    mean_reward     | 23.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 745000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 745472 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 747520 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 749568 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=21.63 +/- 13.50\n",
      "Episode length: 999.20 +/- 327.43\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 999      |\n",
      "|    mean_reward     | 21.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 750000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 751616 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 753664 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=755000, episode_reward=24.88 +/- 11.71\n",
      "Episode length: 1106.00 +/- 302.05\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.11e+03 |\n",
      "|    mean_reward     | 24.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 755000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 755712 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 757760 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 759808 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=24.96 +/- 13.02\n",
      "Episode length: 1035.00 +/- 315.37\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.04e+03 |\n",
      "|    mean_reward     | 25       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 760000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 761856 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 763904 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=765000, episode_reward=31.59 +/- 0.25\n",
      "Episode length: 1156.60 +/- 24.53\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 31.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 765000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 765952 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 768000 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=28.93 +/- 4.17\n",
      "Episode length: 1220.80 +/- 100.21\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.22e+03 |\n",
      "|    mean_reward     | 28.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 770000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 770048 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 772096 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 774144 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=775000, episode_reward=25.34 +/- 7.11\n",
      "Episode length: 1155.60 +/- 89.43\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 25.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 775000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 776192 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 778240 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=24.74 +/- 12.88\n",
      "Episode length: 1063.60 +/- 312.52\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.06e+03 |\n",
      "|    mean_reward     | 24.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 780000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 780288 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 782336 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 784384 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=785000, episode_reward=25.83 +/- 11.13\n",
      "Episode length: 1263.00 +/- 171.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.26e+03 |\n",
      "|    mean_reward     | 25.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 785000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 786432 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 788480 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=20.03 +/- 14.40\n",
      "Episode length: 1165.60 +/- 275.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.17e+03 |\n",
      "|    mean_reward     | 20       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 790000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 790528 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 792576 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 794624 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=795000, episode_reward=22.39 +/- 12.39\n",
      "Episode length: 1002.80 +/- 280.36\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 22.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 795000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 796672 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 798720 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=18.40 +/- 16.06\n",
      "Episode length: 851.20 +/- 406.42\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 851      |\n",
      "|    mean_reward     | 18.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 800000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 800768 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 802816 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 804864 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=805000, episode_reward=31.64 +/- 0.35\n",
      "Episode length: 1160.00 +/- 27.13\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 31.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 805000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 806912 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 808960 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=31.56 +/- 0.22\n",
      "Episode length: 1158.80 +/- 26.21\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 31.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 810000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 811008 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 813056 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=815000, episode_reward=19.17 +/- 14.74\n",
      "Episode length: 929.40 +/- 319.74\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 929      |\n",
      "|    mean_reward     | 19.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 815000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 815104 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 817152 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 819200 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=31.52 +/- 0.32\n",
      "Episode length: 1165.60 +/- 28.05\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.17e+03 |\n",
      "|    mean_reward     | 31.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 820000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 821248 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 823296 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=825000, episode_reward=27.08 +/- 7.95\n",
      "Episode length: 1159.20 +/- 139.76\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 27.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 825000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 825344 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 827392 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 829440 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=4.24 +/- 13.20\n",
      "Episode length: 528.20 +/- 371.66\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 528      |\n",
      "|    mean_reward     | 4.24     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 830000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 44     |\n",
      "|    total_timesteps | 831488 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 833536 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=835000, episode_reward=31.07 +/- 0.37\n",
      "Episode length: 1242.40 +/- 52.63\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.24e+03 |\n",
      "|    mean_reward     | 31.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 835000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 835584 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 837632 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 839680 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=24.39 +/- 9.54\n",
      "Episode length: 1163.80 +/- 278.25\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 24.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 840000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 841728 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 843776 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=845000, episode_reward=22.54 +/- 12.61\n",
      "Episode length: 1033.00 +/- 338.46\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.03e+03 |\n",
      "|    mean_reward     | 22.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 845000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 845824 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 847872 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 849920 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=31.23 +/- 0.61\n",
      "Episode length: 1218.80 +/- 72.08\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.22e+03 |\n",
      "|    mean_reward     | 31.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 850000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 851968 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 854016 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=855000, episode_reward=31.38 +/- 0.15\n",
      "Episode length: 1207.20 +/- 7.91\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.21e+03 |\n",
      "|    mean_reward     | 31.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 855000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 856064 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 858112 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=19.78 +/- 13.69\n",
      "Episode length: 967.00 +/- 337.29\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 967      |\n",
      "|    mean_reward     | 19.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 860000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 860160 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 862208 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 864256 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=865000, episode_reward=9.57 +/- 12.89\n",
      "Episode length: 721.00 +/- 349.76\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 721      |\n",
      "|    mean_reward     | 9.57     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 865000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 866304 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 868352 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=14.38 +/- 14.19\n",
      "Episode length: 824.40 +/- 319.09\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 824      |\n",
      "|    mean_reward     | 14.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 870000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 870400 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 872448 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 874496 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=875000, episode_reward=12.65 +/- 14.92\n",
      "Episode length: 779.20 +/- 393.75\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 779      |\n",
      "|    mean_reward     | 12.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 875000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 876544 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 878592 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=7.99 +/- 7.29\n",
      "Episode length: 796.40 +/- 292.39\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 796      |\n",
      "|    mean_reward     | 7.99     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 880000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 880640 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 882688 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 884736 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=885000, episode_reward=24.67 +/- 13.92\n",
      "Episode length: 1022.40 +/- 315.92\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.02e+03 |\n",
      "|    mean_reward     | 24.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 885000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 886784 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 888832 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=9.11 +/- 18.29\n",
      "Episode length: 627.80 +/- 492.13\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 628      |\n",
      "|    mean_reward     | 9.11     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 890000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 44     |\n",
      "|    total_timesteps | 890880 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 892928 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 894976 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=895000, episode_reward=31.42 +/- 0.27\n",
      "Episode length: 1228.20 +/- 51.77\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.23e+03 |\n",
      "|    mean_reward     | 31.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 895000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 897024 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 899072 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=13.95 +/- 15.88\n",
      "Episode length: 790.80 +/- 380.87\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 791      |\n",
      "|    mean_reward     | 14       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 900000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 901120 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 903168 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=905000, episode_reward=19.83 +/- 14.06\n",
      "Episode length: 952.00 +/- 372.16\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 952      |\n",
      "|    mean_reward     | 19.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 905000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 905216 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 907264 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 909312 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=910000, episode_reward=25.08 +/- 7.77\n",
      "Episode length: 1171.40 +/- 154.10\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.17e+03 |\n",
      "|    mean_reward     | 25.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 910000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 911360 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 913408 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=915000, episode_reward=28.20 +/- 6.12\n",
      "Episode length: 1200.80 +/- 75.93\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 28.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 915000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 47     |\n",
      "|    total_timesteps | 915456 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 917504 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 919552 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=14.49 +/- 8.64\n",
      "Episode length: 948.40 +/- 205.99\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 948      |\n",
      "|    mean_reward     | 14.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 920000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 921600 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 923648 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=925000, episode_reward=20.82 +/- 10.30\n",
      "Episode length: 1070.40 +/- 247.86\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.07e+03 |\n",
      "|    mean_reward     | 20.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 925000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 925696 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 927744 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 929792 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=22.49 +/- 11.11\n",
      "Episode length: 1054.20 +/- 262.26\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.05e+03 |\n",
      "|    mean_reward     | 22.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 930000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 931840 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 933888 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=935000, episode_reward=8.19 +/- 5.48\n",
      "Episode length: 712.60 +/- 197.49\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 713      |\n",
      "|    mean_reward     | 8.19     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 935000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 935936 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 937984 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=25.35 +/- 12.56\n",
      "Episode length: 1040.40 +/- 283.78\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.04e+03 |\n",
      "|    mean_reward     | 25.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 940000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 940032 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 942080 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 944128 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=945000, episode_reward=14.71 +/- 14.96\n",
      "Episode length: 823.80 +/- 415.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 824      |\n",
      "|    mean_reward     | 14.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 945000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 946176 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 948224 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=18.90 +/- 11.53\n",
      "Episode length: 963.60 +/- 293.38\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 964      |\n",
      "|    mean_reward     | 18.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 950000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 950272 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 952320 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 954368 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=955000, episode_reward=24.06 +/- 14.84\n",
      "Episode length: 1007.40 +/- 369.29\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.01e+03 |\n",
      "|    mean_reward     | 24.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 955000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 956416 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 958464 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=12.17 +/- 16.41\n",
      "Episode length: 719.80 +/- 425.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 720      |\n",
      "|    mean_reward     | 12.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 960000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 960512 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 962560 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 964608 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=965000, episode_reward=4.81 +/- 13.66\n",
      "Episode length: 539.20 +/- 334.72\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 539      |\n",
      "|    mean_reward     | 4.81     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 965000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 45     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 44     |\n",
      "|    total_timesteps | 966656 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 968704 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=23.70 +/- 9.59\n",
      "Episode length: 1069.80 +/- 195.53\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.07e+03 |\n",
      "|    mean_reward     | 23.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 970000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 970752 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 972800 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 974848 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=975000, episode_reward=19.83 +/- 14.15\n",
      "Episode length: 995.00 +/- 383.29\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 995      |\n",
      "|    mean_reward     | 19.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 975000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 976896 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 47     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 978944 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=19.27 +/- 12.23\n",
      "Episode length: 1016.20 +/- 332.75\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.02e+03 |\n",
      "|    mean_reward     | 19.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 980000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 980992 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 983040 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=985000, episode_reward=15.45 +/- 14.43\n",
      "Episode length: 852.40 +/- 375.84\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 852      |\n",
      "|    mean_reward     | 15.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 985000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 45     |\n",
      "|    total_timesteps | 985088 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 987136 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 989184 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=23.87 +/- 14.63\n",
      "Episode length: 1038.20 +/- 366.99\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.04e+03 |\n",
      "|    mean_reward     | 23.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 990000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 44     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 991232 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 993280 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=995000, episode_reward=14.69 +/- 8.74\n",
      "Episode length: 1150.40 +/- 322.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.15e+03 |\n",
      "|    mean_reward     | 14.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 995000   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 43     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 46     |\n",
      "|    total_timesteps | 995328 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 997376 |\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 48     |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 42     |\n",
      "|    total_timesteps | 999424 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=26.07 +/- 10.19\n",
      "Episode length: 1159.20 +/- 188.90\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 26.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1000000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1001472 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1003520 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1005000, episode_reward=22.35 +/- 13.11\n",
      "Episode length: 1049.00 +/- 338.76\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.05e+03 |\n",
      "|    mean_reward     | 22.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1005000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1005568 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1007616 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1009664 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1010000, episode_reward=14.43 +/- 14.17\n",
      "Episode length: 839.40 +/- 368.52\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 839      |\n",
      "|    mean_reward     | 14.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1010000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1011712 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1013760 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1015000, episode_reward=23.13 +/- 10.03\n",
      "Episode length: 1124.80 +/- 144.13\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.12e+03 |\n",
      "|    mean_reward     | 23.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1015000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1015808 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1017856 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1019904 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=31.26 +/- 0.21\n",
      "Episode length: 1246.80 +/- 28.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.25e+03 |\n",
      "|    mean_reward     | 31.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1020000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1021952 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1024000 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1025000, episode_reward=31.32 +/- 0.23\n",
      "Episode length: 1231.60 +/- 30.95\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.23e+03 |\n",
      "|    mean_reward     | 31.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1025000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1026048 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1028096 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1030000, episode_reward=31.35 +/- 0.77\n",
      "Episode length: 1239.00 +/- 115.60\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.24e+03 |\n",
      "|    mean_reward     | 31.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1030000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1030144 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1032192 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1034240 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1035000, episode_reward=11.07 +/- 12.56\n",
      "Episode length: 818.40 +/- 338.64\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 818      |\n",
      "|    mean_reward     | 11.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1035000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1036288 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1038336 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=12.62 +/- 15.59\n",
      "Episode length: 996.20 +/- 491.37\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 996      |\n",
      "|    mean_reward     | 12.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1040000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1040384 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1042432 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1044480 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1045000, episode_reward=9.54 +/- 13.23\n",
      "Episode length: 712.40 +/- 386.83\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 712      |\n",
      "|    mean_reward     | 9.54     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1045000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1046528 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1048576 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1050000, episode_reward=24.90 +/- 13.72\n",
      "Episode length: 1026.40 +/- 353.54\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.03e+03 |\n",
      "|    mean_reward     | 24.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1050000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1050624 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1052672 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1054720 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1055000, episode_reward=24.62 +/- 14.06\n",
      "Episode length: 1024.40 +/- 367.66\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.02e+03 |\n",
      "|    mean_reward     | 24.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1055000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1056768 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1058816 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1060000, episode_reward=22.62 +/- 10.67\n",
      "Episode length: 1081.40 +/- 246.09\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.08e+03 |\n",
      "|    mean_reward     | 22.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1060000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1060864 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1062912 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1064960 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1065000, episode_reward=16.77 +/- 14.09\n",
      "Episode length: 956.60 +/- 413.47\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 957      |\n",
      "|    mean_reward     | 16.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1065000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1067008 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1069056 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1070000, episode_reward=27.00 +/- 9.26\n",
      "Episode length: 1156.00 +/- 176.70\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 27       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1070000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1071104 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1073152 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1075000, episode_reward=27.02 +/- 9.02\n",
      "Episode length: 1129.40 +/- 220.22\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.13e+03 |\n",
      "|    mean_reward     | 27       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1075000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1075200 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1077248 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1079296 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=19.18 +/- 16.21\n",
      "Episode length: 891.80 +/- 353.44\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 892      |\n",
      "|    mean_reward     | 19.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1080000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1081344 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1083392 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1085000, episode_reward=20.13 +/- 13.58\n",
      "Episode length: 1014.00 +/- 409.04\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.01e+03 |\n",
      "|    mean_reward     | 20.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1085000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1085440 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1087488 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1089536 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1090000, episode_reward=11.67 +/- 16.62\n",
      "Episode length: 809.20 +/- 432.86\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 809      |\n",
      "|    mean_reward     | 11.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1090000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1091584 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1093632 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1095000, episode_reward=25.42 +/- 12.20\n",
      "Episode length: 1111.20 +/- 314.34\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.11e+03 |\n",
      "|    mean_reward     | 25.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1095000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1095680 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1097728 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1099776 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=12.59 +/- 16.47\n",
      "Episode length: 739.00 +/- 441.19\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 739      |\n",
      "|    mean_reward     | 12.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1100000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1101824 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1103872 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1105000, episode_reward=27.25 +/- 8.36\n",
      "Episode length: 1185.20 +/- 163.34\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 27.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1105000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1105920 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1107968 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1110000, episode_reward=31.57 +/- 0.68\n",
      "Episode length: 1248.80 +/- 87.52\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.25e+03 |\n",
      "|    mean_reward     | 31.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1110000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1110016 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1112064 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1114112 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1115000, episode_reward=26.82 +/- 9.46\n",
      "Episode length: 1152.40 +/- 204.10\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.15e+03 |\n",
      "|    mean_reward     | 26.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1115000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1116160 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1118208 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=19.57 +/- 14.64\n",
      "Episode length: 1167.60 +/- 351.59\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.17e+03 |\n",
      "|    mean_reward     | 19.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1120000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1120256 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1122304 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1124352 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1125000, episode_reward=21.33 +/- 12.60\n",
      "Episode length: 1018.80 +/- 285.94\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.02e+03 |\n",
      "|    mean_reward     | 21.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1125000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1126400 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1128448 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1130000, episode_reward=27.11 +/- 9.56\n",
      "Episode length: 1112.80 +/- 211.68\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.11e+03 |\n",
      "|    mean_reward     | 27.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1130000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1130496 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1132544 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1134592 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1135000, episode_reward=20.85 +/- 9.99\n",
      "Episode length: 1060.80 +/- 147.79\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.06e+03 |\n",
      "|    mean_reward     | 20.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1135000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1136640 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1138688 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1140000, episode_reward=18.82 +/- 16.10\n",
      "Episode length: 882.60 +/- 390.86\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 883      |\n",
      "|    mean_reward     | 18.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1140000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1140736 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1142784 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1144832 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1145000, episode_reward=8.72 +/- 13.51\n",
      "Episode length: 617.00 +/- 349.51\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 617      |\n",
      "|    mean_reward     | 8.72     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1145000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 44      |\n",
      "|    total_timesteps | 1146880 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1148928 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1150000, episode_reward=32.03 +/- 0.50\n",
      "Episode length: 1191.60 +/- 62.22\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 32       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1150000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1150976 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1153024 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1155000, episode_reward=28.85 +/- 6.06\n",
      "Episode length: 1185.60 +/- 76.61\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 28.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1155000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1155072 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1157120 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1159168 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=25.96 +/- 11.97\n",
      "Episode length: 1053.00 +/- 291.84\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.05e+03 |\n",
      "|    mean_reward     | 26       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1160000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1161216 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1163264 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1165000, episode_reward=31.90 +/- 0.67\n",
      "Episode length: 1217.60 +/- 72.52\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.22e+03 |\n",
      "|    mean_reward     | 31.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1165000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1165312 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1167360 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1169408 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1170000, episode_reward=29.39 +/- 4.76\n",
      "Episode length: 1246.80 +/- 60.12\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.25e+03 |\n",
      "|    mean_reward     | 29.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1170000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1171456 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1173504 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1175000, episode_reward=27.92 +/- 7.93\n",
      "Episode length: 1135.20 +/- 126.71\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.14e+03 |\n",
      "|    mean_reward     | 27.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1175000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1175552 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1177600 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1179648 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1180000, episode_reward=32.22 +/- 0.20\n",
      "Episode length: 1177.60 +/- 30.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.18e+03 |\n",
      "|    mean_reward     | 32.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1180000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1181696 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1183744 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1185000, episode_reward=22.71 +/- 12.44\n",
      "Episode length: 1046.00 +/- 326.31\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.05e+03 |\n",
      "|    mean_reward     | 22.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1185000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1185792 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1187840 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1189888 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1190000, episode_reward=28.36 +/- 7.65\n",
      "Episode length: 1114.20 +/- 107.81\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.11e+03 |\n",
      "|    mean_reward     | 28.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1190000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1191936 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1193984 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1195000, episode_reward=25.66 +/- 12.31\n",
      "Episode length: 1053.20 +/- 320.78\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.05e+03 |\n",
      "|    mean_reward     | 25.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1195000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1196032 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1198080 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=29.82 +/- 4.41\n",
      "Episode length: 1180.20 +/- 53.45\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.18e+03 |\n",
      "|    mean_reward     | 29.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1200000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1200128 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1202176 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1204224 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1205000, episode_reward=32.11 +/- 0.48\n",
      "Episode length: 1192.40 +/- 57.36\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 32.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1205000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1206272 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1208320 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1210000, episode_reward=29.56 +/- 4.93\n",
      "Episode length: 1194.00 +/- 36.09\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 29.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1210000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1210368 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1212416 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1214464 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1215000, episode_reward=31.70 +/- 0.59\n",
      "Episode length: 1234.40 +/- 68.21\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.23e+03 |\n",
      "|    mean_reward     | 31.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1215000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1216512 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1218560 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=32.08 +/- 0.21\n",
      "Episode length: 1182.60 +/- 35.55\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.18e+03 |\n",
      "|    mean_reward     | 32.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1220000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1220608 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1222656 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1224704 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1225000, episode_reward=27.02 +/- 8.88\n",
      "Episode length: 1186.20 +/- 197.39\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.19e+03 |\n",
      "|    mean_reward     | 27       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1225000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1226752 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1228800 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1230000, episode_reward=32.04 +/- 0.26\n",
      "Episode length: 1198.60 +/- 27.31\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 32       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1230000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1230848 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1232896 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1234944 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1235000, episode_reward=31.74 +/- 0.57\n",
      "Episode length: 1238.20 +/- 61.95\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.24e+03 |\n",
      "|    mean_reward     | 31.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1235000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1236992 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1239040 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=24.90 +/- 14.07\n",
      "Episode length: 1048.20 +/- 386.86\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.05e+03 |\n",
      "|    mean_reward     | 24.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1240000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1241088 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1243136 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1245000, episode_reward=19.87 +/- 14.74\n",
      "Episode length: 933.00 +/- 354.81\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 933      |\n",
      "|    mean_reward     | 19.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1245000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1245184 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1247232 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1249280 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1250000, episode_reward=25.69 +/- 8.47\n",
      "Episode length: 1090.00 +/- 146.13\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.09e+03 |\n",
      "|    mean_reward     | 25.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1250000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1251328 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1253376 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1255000, episode_reward=32.14 +/- 0.14\n",
      "Episode length: 1205.80 +/- 20.73\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.21e+03 |\n",
      "|    mean_reward     | 32.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1255000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1255424 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1257472 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 47      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1259520 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=21.75 +/- 10.82\n",
      "Episode length: 1133.20 +/- 332.01\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.13e+03 |\n",
      "|    mean_reward     | 21.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1260000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1261568 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1263616 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1265000, episode_reward=32.24 +/- 0.21\n",
      "Episode length: 1201.60 +/- 26.63\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.2e+03  |\n",
      "|    mean_reward     | 32.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1265000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1265664 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 47      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1267712 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1269760 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1270000, episode_reward=25.04 +/- 13.98\n",
      "Episode length: 1040.40 +/- 355.37\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.04e+03 |\n",
      "|    mean_reward     | 25       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1270000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1271808 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1273856 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1275000, episode_reward=27.17 +/- 10.58\n",
      "Episode length: 1078.00 +/- 216.99\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.08e+03 |\n",
      "|    mean_reward     | 27.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1275000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1275904 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1277952 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=32.20 +/- 0.37\n",
      "Episode length: 1211.40 +/- 36.91\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.21e+03 |\n",
      "|    mean_reward     | 32.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1280000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1280000 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1282048 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1284096 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1285000, episode_reward=19.83 +/- 14.78\n",
      "Episode length: 929.80 +/- 361.18\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 930      |\n",
      "|    mean_reward     | 19.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1285000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1286144 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1288192 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1290000, episode_reward=26.01 +/- 12.93\n",
      "Episode length: 1013.80 +/- 304.46\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.01e+03 |\n",
      "|    mean_reward     | 26       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1290000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1290240 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1292288 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1294336 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1295000, episode_reward=28.23 +/- 8.00\n",
      "Episode length: 1127.80 +/- 118.86\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.13e+03 |\n",
      "|    mean_reward     | 28.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1295000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1296384 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1298432 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=32.02 +/- 0.73\n",
      "Episode length: 1220.00 +/- 98.67\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.22e+03 |\n",
      "|    mean_reward     | 32       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1300000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1300480 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1302528 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1304576 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1305000, episode_reward=27.20 +/- 10.10\n",
      "Episode length: 1078.60 +/- 230.55\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.08e+03 |\n",
      "|    mean_reward     | 27.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1305000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1306624 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1308672 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1310000, episode_reward=24.27 +/- 10.12\n",
      "Episode length: 1051.60 +/- 172.24\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.05e+03 |\n",
      "|    mean_reward     | 24.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1310000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1310720 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1312768 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1314816 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1315000, episode_reward=29.37 +/- 5.82\n",
      "Episode length: 1150.20 +/- 87.16\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.15e+03 |\n",
      "|    mean_reward     | 29.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1315000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1316864 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1318912 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1320000, episode_reward=21.66 +/- 10.13\n",
      "Episode length: 1009.80 +/- 233.23\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.01e+03 |\n",
      "|    mean_reward     | 21.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1320000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1320960 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1323008 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1325000, episode_reward=19.04 +/- 16.26\n",
      "Episode length: 869.40 +/- 387.07\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 869      |\n",
      "|    mean_reward     | 19       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1325000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1325056 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1327104 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1329152 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1330000, episode_reward=28.86 +/- 7.33\n",
      "Episode length: 1104.60 +/- 114.18\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.1e+03  |\n",
      "|    mean_reward     | 28.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1330000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1331200 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1333248 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1335000, episode_reward=30.29 +/- 4.46\n",
      "Episode length: 1164.00 +/- 26.01\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 30.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1335000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1335296 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 47      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1337344 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1339392 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1340000, episode_reward=29.08 +/- 5.45\n",
      "Episode length: 1263.40 +/- 43.57\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.26e+03 |\n",
      "|    mean_reward     | 29.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1340000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1341440 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1343488 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1345000, episode_reward=26.92 +/- 10.50\n",
      "Episode length: 1104.80 +/- 234.82\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.1e+03  |\n",
      "|    mean_reward     | 26.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1345000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1345536 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1347584 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1349632 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1350000, episode_reward=20.30 +/- 15.35\n",
      "Episode length: 886.80 +/- 343.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 887      |\n",
      "|    mean_reward     | 20.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1350000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1351680 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1353728 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1355000, episode_reward=20.91 +/- 14.10\n",
      "Episode length: 903.20 +/- 329.70\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 903      |\n",
      "|    mean_reward     | 20.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1355000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1355776 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1357824 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1359872 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=26.45 +/- 11.89\n",
      "Episode length: 1074.80 +/- 207.52\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.07e+03 |\n",
      "|    mean_reward     | 26.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1360000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1361920 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1363968 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1365000, episode_reward=17.46 +/- 12.74\n",
      "Episode length: 859.80 +/- 268.13\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 860      |\n",
      "|    mean_reward     | 17.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1365000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1366016 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1368064 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1370000, episode_reward=32.49 +/- 0.26\n",
      "Episode length: 1159.00 +/- 40.21\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 32.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1370000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1370112 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1372160 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1374208 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1375000, episode_reward=27.88 +/- 9.07\n",
      "Episode length: 1073.00 +/- 186.09\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.07e+03 |\n",
      "|    mean_reward     | 27.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1375000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1376256 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1378304 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1380000, episode_reward=20.06 +/- 12.44\n",
      "Episode length: 998.00 +/- 302.88\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 998      |\n",
      "|    mean_reward     | 20.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1380000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1380352 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1382400 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1384448 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1385000, episode_reward=30.31 +/- 4.62\n",
      "Episode length: 1154.60 +/- 32.11\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.15e+03 |\n",
      "|    mean_reward     | 30.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1385000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1386496 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1388544 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1390000, episode_reward=17.28 +/- 13.49\n",
      "Episode length: 858.40 +/- 301.70\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 858      |\n",
      "|    mean_reward     | 17.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1390000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1390592 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1392640 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1394688 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1395000, episode_reward=27.38 +/- 10.49\n",
      "Episode length: 1072.20 +/- 192.29\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.07e+03 |\n",
      "|    mean_reward     | 27.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1395000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1396736 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1398784 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=12.75 +/- 13.51\n",
      "Episode length: 788.60 +/- 387.55\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 789      |\n",
      "|    mean_reward     | 12.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1400000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1400832 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1402880 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1404928 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1405000, episode_reward=14.26 +/- 14.80\n",
      "Episode length: 784.00 +/- 369.19\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 784      |\n",
      "|    mean_reward     | 14.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1405000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1406976 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1409024 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1410000, episode_reward=12.28 +/- 12.82\n",
      "Episode length: 739.20 +/- 352.16\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 739      |\n",
      "|    mean_reward     | 12.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1410000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1411072 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1413120 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1415000, episode_reward=18.25 +/- 12.50\n",
      "Episode length: 915.80 +/- 277.87\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 916      |\n",
      "|    mean_reward     | 18.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1415000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1415168 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1417216 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1419264 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=20.58 +/- 14.91\n",
      "Episode length: 903.40 +/- 337.14\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 903      |\n",
      "|    mean_reward     | 20.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1420000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1421312 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1423360 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1425000, episode_reward=13.45 +/- 15.90\n",
      "Episode length: 749.40 +/- 396.72\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 749      |\n",
      "|    mean_reward     | 13.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1425000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1425408 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1427456 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1429504 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1430000, episode_reward=16.70 +/- 14.43\n",
      "Episode length: 895.20 +/- 362.22\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 895      |\n",
      "|    mean_reward     | 16.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1430000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1431552 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1433600 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1435000, episode_reward=16.81 +/- 18.77\n",
      "Episode length: 806.00 +/- 480.24\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 806      |\n",
      "|    mean_reward     | 16.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1435000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1435648 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1437696 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1439744 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=18.19 +/- 12.84\n",
      "Episode length: 888.80 +/- 290.34\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 889      |\n",
      "|    mean_reward     | 18.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1440000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1441792 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1443840 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1445000, episode_reward=21.28 +/- 9.99\n",
      "Episode length: 997.00 +/- 222.39\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 997      |\n",
      "|    mean_reward     | 21.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1445000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1445888 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1447936 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1449984 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1450000, episode_reward=16.39 +/- 9.79\n",
      "Episode length: 896.80 +/- 274.52\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 897      |\n",
      "|    mean_reward     | 16.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1450000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1452032 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1454080 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1455000, episode_reward=12.05 +/- 16.58\n",
      "Episode length: 680.40 +/- 410.62\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 680      |\n",
      "|    mean_reward     | 12       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1455000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 44      |\n",
      "|    total_timesteps | 1456128 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1458176 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=17.82 +/- 12.53\n",
      "Episode length: 875.20 +/- 267.37\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 875      |\n",
      "|    mean_reward     | 17.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1460000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1460224 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1462272 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1464320 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1465000, episode_reward=11.29 +/- 17.81\n",
      "Episode length: 657.60 +/- 442.10\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 658      |\n",
      "|    mean_reward     | 11.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1465000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1466368 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1468416 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1470000, episode_reward=20.27 +/- 14.80\n",
      "Episode length: 934.00 +/- 370.49\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 934      |\n",
      "|    mean_reward     | 20.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1470000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1470464 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1472512 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1474560 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1475000, episode_reward=21.96 +/- 14.26\n",
      "Episode length: 946.60 +/- 349.89\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 947      |\n",
      "|    mean_reward     | 22       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1475000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1476608 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1478656 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=26.29 +/- 12.76\n",
      "Episode length: 1006.60 +/- 298.61\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.01e+03 |\n",
      "|    mean_reward     | 26.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1480000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1480704 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1482752 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1484800 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1485000, episode_reward=24.20 +/- 10.32\n",
      "Episode length: 1001.40 +/- 179.63\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 24.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1485000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1486848 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1488896 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1490000, episode_reward=11.01 +/- 17.82\n",
      "Episode length: 627.80 +/- 401.17\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 628      |\n",
      "|    mean_reward     | 11       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1490000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 44      |\n",
      "|    total_timesteps | 1490944 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1492992 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1495000, episode_reward=27.09 +/- 6.34\n",
      "Episode length: 1247.80 +/- 176.58\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.25e+03 |\n",
      "|    mean_reward     | 27.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1495000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1495040 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1497088 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1499136 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1500000, episode_reward=15.53 +/- 14.09\n",
      "Episode length: 820.00 +/- 337.81\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 820      |\n",
      "|    mean_reward     | 15.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1500000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1501184 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1503232 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1505000, episode_reward=20.40 +/- 15.04\n",
      "Episode length: 883.80 +/- 298.22\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 884      |\n",
      "|    mean_reward     | 20.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1505000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1505280 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1507328 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1509376 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1510000, episode_reward=15.10 +/- 15.00\n",
      "Episode length: 842.80 +/- 362.84\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 843      |\n",
      "|    mean_reward     | 15.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1510000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1511424 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1513472 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1515000, episode_reward=13.70 +/- 15.55\n",
      "Episode length: 741.60 +/- 367.49\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 742      |\n",
      "|    mean_reward     | 13.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1515000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1515520 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 47      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1517568 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1519616 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=22.20 +/- 13.99\n",
      "Episode length: 972.60 +/- 244.22\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 973      |\n",
      "|    mean_reward     | 22.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1520000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1521664 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1523712 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1525000, episode_reward=19.82 +/- 15.53\n",
      "Episode length: 852.00 +/- 339.95\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 852      |\n",
      "|    mean_reward     | 19.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1525000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1525760 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1527808 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1529856 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1530000, episode_reward=12.57 +/- 11.41\n",
      "Episode length: 777.20 +/- 277.69\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 777      |\n",
      "|    mean_reward     | 12.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1530000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1531904 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1533952 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1535000, episode_reward=14.12 +/- 10.74\n",
      "Episode length: 809.60 +/- 261.85\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 810      |\n",
      "|    mean_reward     | 14.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1535000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1536000 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1538048 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1540000, episode_reward=8.50 +/- 13.98\n",
      "Episode length: 637.40 +/- 347.20\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 637      |\n",
      "|    mean_reward     | 8.5      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1540000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 44      |\n",
      "|    total_timesteps | 1540096 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1542144 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1544192 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1545000, episode_reward=15.96 +/- 13.81\n",
      "Episode length: 809.40 +/- 324.23\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 809      |\n",
      "|    mean_reward     | 16       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1545000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1546240 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1548288 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1550000, episode_reward=22.81 +/- 12.18\n",
      "Episode length: 986.00 +/- 253.73\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 986      |\n",
      "|    mean_reward     | 22.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1550000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1550336 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1552384 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1554432 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1555000, episode_reward=19.28 +/- 10.90\n",
      "Episode length: 1057.80 +/- 343.45\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.06e+03 |\n",
      "|    mean_reward     | 19.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1555000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1556480 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1558528 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1560000, episode_reward=18.47 +/- 16.45\n",
      "Episode length: 846.40 +/- 421.87\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 846      |\n",
      "|    mean_reward     | 18.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1560000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1560576 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1562624 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1564672 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1565000, episode_reward=16.57 +/- 14.81\n",
      "Episode length: 841.80 +/- 364.90\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 842      |\n",
      "|    mean_reward     | 16.6     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1565000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1566720 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1568768 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1570000, episode_reward=28.33 +/- 7.61\n",
      "Episode length: 1086.20 +/- 137.82\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.09e+03 |\n",
      "|    mean_reward     | 28.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1570000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1570816 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1572864 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1574912 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1575000, episode_reward=32.31 +/- 0.35\n",
      "Episode length: 1142.20 +/- 23.39\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.14e+03 |\n",
      "|    mean_reward     | 32.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1575000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1576960 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1579008 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1580000, episode_reward=25.66 +/- 12.52\n",
      "Episode length: 1040.80 +/- 328.85\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.04e+03 |\n",
      "|    mean_reward     | 25.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1580000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1581056 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1583104 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1585000, episode_reward=12.21 +/- 12.56\n",
      "Episode length: 920.60 +/- 473.32\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 921      |\n",
      "|    mean_reward     | 12.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1585000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1585152 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1587200 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1589248 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1590000, episode_reward=23.54 +/- 12.18\n",
      "Episode length: 988.00 +/- 266.35\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 988      |\n",
      "|    mean_reward     | 23.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1590000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1591296 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1593344 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1595000, episode_reward=26.83 +/- 11.39\n",
      "Episode length: 1010.80 +/- 233.17\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.01e+03 |\n",
      "|    mean_reward     | 26.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1595000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1595392 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1597440 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1599488 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=28.69 +/- 7.58\n",
      "Episode length: 1084.40 +/- 75.83\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.08e+03 |\n",
      "|    mean_reward     | 28.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1600000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1601536 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 44      |\n",
      "|    total_timesteps | 1603584 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1605000, episode_reward=26.50 +/- 11.93\n",
      "Episode length: 1001.60 +/- 260.67\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 26.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1605000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1605632 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1607680 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 47      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 43      |\n",
      "|    total_timesteps | 1609728 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1610000, episode_reward=15.85 +/- 16.48\n",
      "Episode length: 791.80 +/- 425.58\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 792      |\n",
      "|    mean_reward     | 15.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1610000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1611776 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1613824 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1615000, episode_reward=23.15 +/- 17.62\n",
      "Episode length: 1256.80 +/- 172.13\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.26e+03 |\n",
      "|    mean_reward     | 23.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1615000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 42      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1615872 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1617920 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1619968 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1620000, episode_reward=19.76 +/- 15.64\n",
      "Episode length: 863.80 +/- 365.76\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 864      |\n",
      "|    mean_reward     | 19.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1620000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1622016 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1624064 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1625000, episode_reward=29.44 +/- 5.46\n",
      "Episode length: 1158.40 +/- 21.19\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.16e+03 |\n",
      "|    mean_reward     | 29.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1625000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1626112 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1628160 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1630000, episode_reward=17.03 +/- 13.92\n",
      "Episode length: 829.20 +/- 316.14\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 829      |\n",
      "|    mean_reward     | 17       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1630000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 44      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1630208 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1632256 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1634304 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1635000, episode_reward=24.19 +/- 16.38\n",
      "Episode length: 943.60 +/- 407.18\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 944      |\n",
      "|    mean_reward     | 24.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1635000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 47      |\n",
      "|    total_timesteps | 1636352 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1638400 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1640000, episode_reward=28.30 +/- 7.93\n",
      "Episode length: 1094.00 +/- 114.67\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.09e+03 |\n",
      "|    mean_reward     | 28.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1640000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 43      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 46      |\n",
      "|    total_timesteps | 1640448 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1642496 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 48      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1644544 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1645000, episode_reward=13.95 +/- 15.22\n",
      "Episode length: 733.40 +/- 355.54\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 733      |\n",
      "|    mean_reward     | 14       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1645000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1646592 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 47      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1648640 |\n",
      "--------------------------------\n",
      "Eval num_timesteps=1650000, episode_reward=4.24 +/- 14.68\n",
      "Episode length: 479.20 +/- 397.78\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 479      |\n",
      "|    mean_reward     | 4.24     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1650000  |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 45      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 45      |\n",
      "|    total_timesteps | 1650688 |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 47      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 42      |\n",
      "|    total_timesteps | 1652736 |\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "total_timesteps = 100000  # Aumentar el número de timesteps para un entrenamiento más prolongado\n",
    "rewards = []\n",
    "\n",
    "print(\"Entrenando el modelo y registrando recompensas por episodio...\")\n",
    "obs = env.reset()\n",
    "episode_reward = 0\n",
    "\n",
    "for timestep in range(total_timesteps):\n",
    "    action, _ = model.predict(obs, deterministic=False)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    \n",
    "    # Acumular recompensa y renderizar el entorno\n",
    "    episode_reward += reward[0] if isinstance(reward, np.ndarray) else reward\n",
    "    env.render()  # Renderizar el entorno en cada paso para ver la ventana de pygame\n",
    "    time.sleep(0.01)  # Controla la velocidad del renderizado\n",
    "    \n",
    "    if done:\n",
    "        rewards.append(episode_reward)  # Almacenar la recompensa del episodio\n",
    "        obs = env.reset()\n",
    "        episode_reward = 0\n",
    "    \n",
    "    # Ejecutar el aprendizaje y actualizar los parámetros\n",
    "    model.learn(total_timesteps=1, reset_num_timesteps=False, callback=eval_callback)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save(MODEL_PATH)\n",
    "print(\"Modelo entrenado y guardado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion del modelo\n",
    "#### Una vez terminado el entrenamiento lo que hacemos es evaluar el modelo entrenado ejecutando 10,000 pasos en el entorno. En cada paso, el modelo selecciona una acción, se calcula la recompensa, y se acumula en total_reward. El entorno se renderiza en tiempo real, permitiendo visualizar el desempeño del agente, y se controla la velocidad de visualización. Cuando el episodio termina (done), el entorno se reinicia. Finalmente, se imprime la recompensa total acumulada, indicando el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando el modelo...\n",
      "Evaluación completada. Recompensa total acumulada: -9.38\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluando el modelo...\")\n",
    "obs = env.reset()\n",
    "total_reward = 0\n",
    "\n",
    "for _ in range(10000):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    total_reward += reward[0] if isinstance(reward, np.ndarray) else reward\n",
    "    \n",
    "    env.render()  # Renderizar el entorno\n",
    "    time.sleep(0.01)  # Controla la velocidad del renderizado\n",
    "    \n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "        break\n",
    "\n",
    "print(f\"Evaluación completada. Recompensa total acumulada: {float(total_reward):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cierre del entorno**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberar los recursos utilizados por el entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registro de Recompensas Durante el Entrenamiento\n",
    "#### Una vez ya terminamos con todo, entrenamiento y evaluacion, lo que hacemos en esta parte es que, primero aseguramos que la lista rewards contenga solo valores escalares, convirtiendo cualquier valor ndarray en escalar. Luego definimos una función plot_rewards, que grafica las recompensas obtenidas por episodio. La primera gráfica muestra las recompensas acumuladas para cada episodio, y la segunda utiliza un promedio móvil para suavizar la curva y mostrar la tendencia general de las recompensas, facilitando la interpretación del progreso del agente. Finalmente, se llama a plot_rewards para visualizar las recompensas obtenidas durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Asegurarse de que `rewards` contenga solo valores escalares\n",
    "rewards = [reward.item() if isinstance(reward, np.ndarray) else reward for reward in rewards]\n",
    "\n",
    "def plot_rewards(rewards, window=10):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Graficar recompensas acumuladas (sin promedio móvil)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(rewards, color='blue')\n",
    "    plt.title('Recompensas Totales por Episodio')\n",
    "    plt.xlabel('Episodios')\n",
    "    plt.ylabel('Recompensa Total')\n",
    "\n",
    "    # Graficar promedio móvil para suavizar la curva\n",
    "    rolling_mean = np.convolve(rewards, np.ones(window) / window, mode='valid')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(rolling_mean, color='orange')\n",
    "    plt.title(f'Recompensas Promedio (window={window})')\n",
    "    plt.xlabel('Episodios')\n",
    "    plt.ylabel('Recompensa Promedio')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Graficar las recompensas registradas durante el entrenamiento\n",
    "plot_rewards(rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
